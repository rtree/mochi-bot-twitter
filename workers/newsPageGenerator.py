import os
import re
import subprocess
import requests
from datetime import datetime
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urlparse


class NewsPageGenerator:
    def __init__(self, config):
        self.config = config
        # ç¾åœ¨ã®ãƒªãƒã‚¸ãƒˆãƒªå†…ã§GitHub Pagesã‚’ä½¿ç”¨
        self.pages_repo_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        self.posts_dir = os.path.join(self.pages_repo_path, '_posts')
        self.twitter_url = config.TWITTER_PROFILE_URL  # Xã‚¢ã‚«ã‚¦ãƒ³ãƒˆ

    def generate_and_publish(self, all_news_content, urls):
        """
        å…¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ç”Ÿæˆã—ã€GitHubã«push
        
        Args:
            all_news_content: å…¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—ã§åˆ†å‰²æ¸ˆã¿ï¼‰
            urls: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®URLä¸€è¦§
        """
        try:
            # _postsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            os.makedirs(self.posts_dir, exist_ok=True)
            
            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            filepath = self._generate_markdown(all_news_content, urls)
            
            # GitHubã«push
            self._push_to_github(filepath)
            
            self.config.logprint.info(f"News page published successfully: {filepath}")
            return True
            
        except Exception as e:
            self.config.elogprint.error(f"Failed to publish news page: {str(e)}")
            return False

    def _fetch_ogp_image(self, url):
        """URLã‹ã‚‰OGPç”»åƒã‚’å–å¾—"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (compatible; MochiBot/1.0)'}
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # OGPç”»åƒã‚’æ¢ã™
            og_image = soup.find('meta', property='og:image')
            if og_image and og_image.get('content'):
                return og_image['content']
            
            # Twitter Cardç”»åƒã‚’æ¢ã™
            twitter_image = soup.find('meta', attrs={'name': 'twitter:image'})
            if twitter_image and twitter_image.get('content'):
                return twitter_image['content']
            
            return None
        except Exception as e:
            self.config.logprint.warning(f"Failed to fetch OGP image from {url}: {str(e)}")
            return None

    def _extract_title_from_text(self, text):
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã‹ã‚‰çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        # æœ€åˆã®æ–‡ã‚’å–å¾—ã—ã¦çŸ­ãã™ã‚‹
        text = text.strip()
        # æœ€åˆã®å¥ç‚¹ã¾ãŸã¯ã€‚ã§åŒºåˆ‡ã‚‹
        match = re.split(r'[ã€‚ï¼\.ã€]', text)
        if match:
            title = match[0].strip()
            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            if len(title) > 50:
                title = title[:47] + "..."
            return title
        return text[:50] + "..." if len(text) > 50 else text

    def _generate_markdown(self, all_news_content, urls):
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        today = datetime.now()
        date_str = today.strftime('%Y-%m-%d')
        date_display = today.strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å: YYYY-MM-DD-daily-news.md
        filename = f"{date_str}-daily-news.md"
        filepath = os.path.join(self.posts_dir, filename)
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†å‰²ã—ã¦ãƒ‘ãƒ¼ã‚¹
        news_items = all_news_content.split(self.config.TWITTER_DELIMITER)
        news_items = [item.strip() for item in news_items if item.strip()]
        
        # å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ§‹é€ åŒ–
        parsed_items = []
        for item in news_items:
            item = item.strip()
            url = None
            text = item
            
            # URLã‚’æŠ½å‡ºï¼ˆæœ¬æ–‡ä¸­ã®ã©ã“ã«ã‚ã£ã¦ã‚‚å¯¾å¿œï¼‰
            url_match = re.search(r'(https?://[^\s]+)', item)
            if url_match:
                url = url_match.group(1)
                # URLã‚’æœ¬æ–‡ã‹ã‚‰é™¤å»
                text = item.replace(url, '').strip()
            else:
                # URLãŒãªã„è¨˜äº‹ã¯ã‚¹ã‚­ãƒƒãƒ—
                self.config.logprint.warning(f"Skipping news item without URL: {text[:50]}...")
                continue
            
            title = self._extract_title_from_text(text)
            ogp_image = self._fetch_ogp_image(url) if url else None
            
            parsed_items.append({
                'title': title,
                'text': text,
                'url': url,
                'ogp_image': ogp_image
            })
        
        # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã¯æœ€åˆã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰
        main_title = parsed_items[0]['title'] if parsed_items else f"{date_display}ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹"
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
        content = self._build_markdown_content(date_display, main_title, parsed_items, urls)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.config.logprint.info(f"Generated markdown file: {filepath}")
        return filepath

    def _build_markdown_content(self, date_display, main_title, parsed_items, urls):
        """Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰"""
        now = datetime.now()
        
        # Jekyll Front Matter
        content = f"""---
layout: post
title: "{main_title}"
date: {now.strftime('%Y-%m-%d %H:%M:%S')} +0900
categories: news
---

ğŸ“… {date_display} | [ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]({{{{ site.baseurl }}}}/news/) | [@techandeco4242]({self.twitter_url})

Xã«åã¾ã‚Šãã‚‰ãªã‹ã£ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ ğŸ±

---

"""
        # å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ 
        for i, item in enumerate(parsed_items, 1):
            content += f'### {i}. {item["title"]}\n\n'
            content += f'{item["text"]}\n\n'
            
            # OGPç”»åƒãŒã‚ã‚Œã°è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚«ãƒ–ãƒ«ï¼‰
            if item['ogp_image'] and item['url']:
                content += f'[![{item["title"]}]({item["ogp_image"]})]({item["url"]})\n\n'
            
            if item['url']:
                domain = urlparse(item['url']).netloc
                content += f'ğŸ”— [{domain}]({item["url"]})\n\n'
            
            content += '\n---\n\n'

        # ãƒ•ãƒƒã‚¿ãƒ¼
        content += f"""[ğŸ“… éå»ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹]({{{{ site.baseurl }}}}/news/) | [ğŸ± ãƒ†ã‚¯ã®çŒ«ã‚’ãƒ•ã‚©ãƒ­ãƒ¼]({self.twitter_url})
"""
        return content

    def _push_to_github(self, filepath):
        """GitHubã«push"""
        try:
            # git add
            subprocess.run(
                ['git', 'add', filepath],
                cwd=self.pages_repo_path,
                check=True
            )
            
            # git commit
            today = datetime.now().strftime('%Y-%m-%d')
            subprocess.run(
                ['git', 'commit', '-m', f'Add daily news for {today}'],
                cwd=self.pages_repo_path,
                check=True
            )
            
            # git push
            subprocess.run(
                ['git', 'push'],
                cwd=self.pages_repo_path,
                check=True
            )
            
            self.config.logprint.info("Successfully pushed to GitHub")
            
        except subprocess.CalledProcessError as e:
            self.config.elogprint.error(f"Git operation failed: {str(e)}")
            raise
