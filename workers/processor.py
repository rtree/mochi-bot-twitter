import asyncio
from openai import OpenAI

class Processor:
    def __init__(self, context, config):
        self.context  = context
        self.config   = config
        self.aiclient = OpenAI(api_key=config.OPENAI_API_KEY)

    async def summarize_results_async(self, snippets):
        # p_src = (
        #     f"{self.config.CHARACTER}ã€‚ã‚ãªãŸã¯æ¤œç´¢çµæœã‚’è¦ç´„ã—ã€èª¿æŸ»å ±å‘Šã¨ã—ã¦å›ç­”ã‚’ä½œæˆã—ã¾ã™ã€‚"
        #     f" ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¤ã¤ç§ãŒçŸ¥ã‚ŠãŸã„ã“ã¨ã®ä¸»æ—¨ã‚’æŠŠæ¡ã®ä¸Šã§ã€æ¤œç´¢çµæœã‚’è¦ç´„ã—å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„ã€‚"
        #     f" ä»®ã«æ¤œç´¢çµæœãŒè‹±èªã§ã‚‚å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        #     f" ãªãŠã€å›ç­”ãŒã‚ˆã‚Šé«˜å“è³ªã«ãªã‚‹ã®ãªã‚‰ã°ã€ã‚ãªãŸã®å†…éƒ¨çŸ¥è­˜ã‚’åŠ å‘³ã—ã¦å›ç­”ã‚’ä½œã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
        #     f" å›ç­”ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ã“ã¡ã‚‰:"
        #     f" - æ›¸ãå‡ºã—ã¯ ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼ "
        #     f" - æ›¸ãå‡ºã—ã«ç¶šãå…¨è¨˜äº‹ã®ã¾ã¨ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã—ä¸€åº¦{self.config.TWITTER_DELIMITER}ã§åˆ‡ã‚‹"
        #     f" - æŠ•ç¨¿å…ˆã¯X(Twitter)ãªã®ã§ã€Markdownã¯ä½¿ã‚ãªã„ã§ãã ã•ã„"
        #     f" - åŒºåˆ‡ã‚Šã¯1è¨˜äº‹ã”ã¨{self.config.TWITTER_DELIMITER}ã®åŒºåˆ‡ã‚Šæ–‡å­—ã®ã¿ã€‚
        #     180æ–‡å­—ã”ã¨ã«åŒºåˆ‡ã‚‹ã“ã¨ã€‚åŒºåˆ‡ã‚Šæ–‡å­—ã¯æ–‡å­—æ•°ã«å«ã‚ãªã„ã€‚ã¾ãŸã€è¦ç´„ã®å†’é ­ã«ç®‡æ¡æ›¸ããªã©ã® ãƒ» ã¯å«ã‚ãªã„ã§ãã ã•ã„"
        #     f" - å‚è€ƒè¨˜äº‹ã®URLã¯è¦ç´„ã«å«ã‚ãªã„"
        #     f" - è¦ç´„ãŒçµ‚ã‚ã£ãŸå¾Œã«{self.config.TWITTER_DELIMITER}ã§åˆ‡ã£ãŸã®ã¡ã€ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã™ã‚‹ã€‚ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯å†…å®¹ã‹ã‚‰ã„ããªã‚Šæ›¸ãå§‹ã‚ã¦ãã ã•ã„ã€‚ã¤ã¾ã‚Šã€ ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆ ãªã©ã®è¦‹å‡ºã—ã¯ã¤ã‘ãªã„ã§ãã ã•ã„"
        #     f" - è¦ç´„ã®æ–‡ä½“ã‚‚{self.config.AINAME}ã«ãªã‚‹ã‚ˆã†ã«æ°—ã‚’ã¤ã‘ã¦ãã ã•ã„"
        #     f" - æœ€å¾Œã«å‚è€ƒè¨˜äº‹ã®URLã‚’æŠ•ç¨¿ã™ã‚‹"
        #     f" - å‚è€ƒè¨˜äº‹ã®å„URLã®å‰ã«å¿…ãš{self.config.TWITTER_DELIMITER}ã¨æ›¸ãã€æ¬¡ã®è¡Œã«ãƒªãƒ³ã‚¯ã‚’è¨˜è¼‰"
        #     f" ä»¥ä¸‹ãŒè¦ç´„å¯¾è±¡ã®æ¤œç´¢çµæœã§ã™:"
        #     f"  {snippets}"
        # )
        p_src = (
            f"""
            ã‚ãªãŸã¯X(Twitter)æŠ•ç¨¿ç”¨ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã‚’ä½œæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            æ¤œç´¢çµæœã‚’è¦ç´„ã—ã€TwitteræŠ•ç¨¿å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            æ¤œç´¢çµæœãŒè‹±èªã§ã‚‚å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚

            ã€é‡è¦ãªç¦æ­¢äº‹é …ã€‘
            - ã€Œãµãµã‚“ã€ã€Œã‚‚ã¡ãŠã ã‚ˆã€ãªã©ã®æŒ¨æ‹¶ã‚„å‰ç½®ãã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã§ãã ã•ã„
            - ã€Œã»ã‹ã«ã‚‚èª­ã¿ãŸã„è¨˜äº‹ãŒã‚ã£ãŸã‚‰ã€ãªã©ã®å¾Œæ›¸ãã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã§ãã ã•ã„
            - ã€Œ--- Start of content ---ã€ã€Œ--- End of content ---ã€å½¢å¼ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
            - Markdownï¼ˆ**å¤ªå­—**ã€- ç®‡æ¡æ›¸ã ãªã©ï¼‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
            - ã„ããªã‚Š1ã¤ç›®ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„

            ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
            æ¤œç´¢çµæœã®ä¸­ã§é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å¿…ãš9å€‹ä»¥ä¸Šé¸ã‚“ã§ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            
            **é‡è¦ãªåˆ¶ç´„**:
            - 9å€‹æœªæº€ã®å‡ºåŠ›ã¯çµ¶å¯¾ã«ç¦æ­¢ã§ã™
            - æ¤œç´¢çµæœã«ã¯ååˆ†ãªæ•°ã®ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚‹ã®ã§ã€å¿…ãš9å€‹ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„
            - æœ€ä½9å€‹ã€ã§ãã‚Œã°12å€‹ç¨‹åº¦ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„
            - å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯DELIMITERï¼ˆ@@@@@@@@@@ï¼‰ã§åŒºåˆ‡ã£ã¦ãã ã•ã„
            - **å¿…ãšè¦ç´„ã®å¾Œã«URLã‚’è¨˜è¼‰ï¼ˆã€Œãªã—ã€ã‚„çœç•¥ã¯çµ¶å¯¾ç¦æ­¢ï¼‰**

            *è¨˜äº‹è¦ç´„ï¼ˆ1ã€œ3æ–‡ã§ç°¡æ½”ã«ã€‚èªå°¾ã¯ã€Œã ã‚ˆã€ã€Œã ã£ã¦ã€ãªã©æŸ”ã‚‰ã‹ãï¼‰*

            *è¨˜äº‹URLï¼ˆå¿…ãšhttps://ã§å§‹ã¾ã‚‹å®Œå…¨ãªURLã€‚æ¤œç´¢çµæœã‹ã‚‰æŠ½å‡ºã™ã‚‹ã“ã¨ï¼‰*
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹1ã€‘
            Intelã®æ–°GPUã€ŒBattlemageã€ãŒç™ºè¡¨ã•ã‚ŒãŸã‚ˆã€‚æ€§èƒ½ã‚ˆã‚Šã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é‡è¦–ã—ã€VRAMå®¹é‡ã§ç«¶äº‰åŠ›ã‚’é«˜ã‚ã¦ã‚‹ã¿ãŸã„ã€‚ç‰¹ã«$250ã§12GB VRAMæ­è¼‰ã®Arc B580ã¯èˆˆå‘³æ·±ã„ã­

            https://gamersnexus.net/gpus/intel-arc-b580-battlemage-gpu-review-benchmarks
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹2ã€‘
            ãƒ‘ã‚­ã‚¹ã‚¿ãƒ³ã§ã€ŒAIQT 2025ã€ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ãŒé–‹å‚¬ã•ã‚Œã€AIã¨é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã®èåˆã«ã¤ã„ã¦è­°è«–ãŒè¡Œã‚ã‚ŒãŸã‚ˆã€‚å›½éš›çš„ãªå°‚é–€å®¶ãŒé›†ã¾ã‚Šã€é‡å­ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚„AIé§†å‹•ã®é‡å­å›è·¯ãªã©ã®é–‹ç™ºå‹•å‘ãŒç´¹ä»‹ã•ã‚ŒãŸã‚“ã ã£ã¦

            https://www.thenews.com.pk/print/1280851-aiqt-2025
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹3ã€‘
            GitHubãŒAIã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ©Ÿèƒ½ã‚’å¤§å¹…å¼·åŒ–ã—ãŸã‚ˆã€‚æ–°æ©Ÿèƒ½ã«ã‚ˆã‚Šé–‹ç™ºé€Ÿåº¦ãŒå¹³å‡30%å‘ä¸Šã™ã‚‹è¦‹è¾¼ã¿ãªã‚“ã ã£ã¦

            https://github.blog/ai-coding-features
            {self.config.TWITTER_DELIMITER}

            (â€»ã“ã®ã‚ˆã†ã«æœ€ä½9å€‹ä»¥ä¸Šã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é€£ç¶šã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å„è¨˜äº‹ã«å¿…ãšURLã‚’å«ã‚ã‚‹ã“ã¨ï¼)

            ã€å„ãƒ„ã‚¤ãƒ¼ãƒˆã®åˆ¶ç´„ã€‘
            - 1ã¤ç›®ã®ãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰ã„ããªã‚Šå§‹ã‚ã‚‹ï¼ˆå‰ç½®ãç¦æ­¢ï¼‰
            - æœ€å¾Œã®ãƒˆãƒ”ãƒƒã‚¯ã§çµ‚ã‚ã‚‹ï¼ˆå¾Œæ›¸ãç¦æ­¢ï¼‰
            - å„ãƒ„ã‚¤ãƒ¼ãƒˆã¯URLè¾¼ã¿ã§æœ€é•·280æ–‡å­—ï¼ˆURLã¯å¸¸ã«23æ–‡å­—ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼‰
            - åŒºåˆ‡ã‚Šæ–‡å­— {self.config.TWITTER_DELIMITER} ã¯æ–‡å­—æ•°ã«å«ã‚ãªã„
            
            ã€é‡è¦ã€‘æ¤œç´¢çµæœã«ã¯å…¨ã¦URLãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å„è¨˜äº‹ã‹ã‚‰å¿…ãšURLã‚’æŠ½å‡ºã—ã¦ç©ºè¡Œã®å¾Œã«1è¡Œã§è¨˜è¼‰ã—ã¦ãã ã•ã„ï¼ˆã€Œãªã—ã€ç­‰ã¯çµ¶å¯¾ã«å‡ºåŠ›ç¦æ­¢ï¼‰ã€‚

            ã€è¦ç´„å¯¾è±¡ã®æ¤œç´¢çµæœã€‘
            {snippets}
            
            ä¸Šè¨˜ã®æ¤œç´¢çµæœã‹ã‚‰ã€å¿…ãš9å€‹ä»¥ä¸Šã®é‡è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é¸ã‚“ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            """
         )


        def blocking_chat_completion():
            messages = [{"role": "system", "content": self.config.CHARACTER}]
            messages.extend(self.context)
            messages.append({"role": "user", "content": p_src})

            return self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=messages
            )

        response = await asyncio.to_thread(blocking_chat_completion)
        summary = response.choices[0].message.content

        return f"{summary}"

    async def summarize_each_result_async(self, contents):
        summaries = []
        for idx, content in enumerate(contents):
            self.config.logprint.info(f"Starting summarization for content {idx + 1}/{len(contents)}...")
            p_src = (
                f"""ã‚ãªãŸã¯è‘—åãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ã®å‰µæ¥­è€…ã§ã™ã€‚ã‚ãªãŸã¯ä»¥ä¸‹ã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚
                è¦ç´„ã¯ã€ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¤ã¤ç§ãŒçŸ¥ã‚ŠãŸã„ã“ã¨ã®ä¸»æ—¨ã‚’æŠŠæ¡ã®ä¸Šã§ä½œã£ã¦ãã ã•ã„ã€‚
                ä»®ã«å†…å®¹ãŒè‹±èªã§ã‚‚å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
                ãªãŠã€å›ç­”ãŒã‚ˆã‚Šé«˜å“è³ªã«ãªã‚‹ã®ãªã‚‰ã°ã€ã‚ãªãŸã®å†…éƒ¨çŸ¥è­˜ã‚’åŠ å‘³ã—ã¦å›ç­”ã‚’ä½œã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
                å›ç­”ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä»¥ä¸‹ã§ãŠé¡˜ã„ã—ã¾ã™:

                {self.config.FETCHER_START_OF_CONTENT}
                Title: *è¦ç´„å‰ã®Title*
                URL: *è¦ç´„å‰ã®URL*
                SRC: *è¦ç´„å‰ã®SRC*
                Snippet: *è¦ç´„çµæœ*
                {self.config.FETCHER_END_OF_CONTENT}

                ä»¥ä¸‹ãŒè¦ç´„å¯¾è±¡ã®å†…å®¹ã§ã™:
                 {content}
                """
            )

            def blocking_chat_completion():
                messages = [{"role": "system", "content": self.config.CHARACTER}]
                messages.extend(self.context)
                messages.append({"role": "user", "content": p_src})

                return self.aiclient.chat.completions.create(
                    model=self.config.OPENAI_GPT_MODEL,
                    messages=messages
                )

            try:
                response = await asyncio.to_thread(blocking_chat_completion)
                summary = response.choices[0].message.content
                summaries.append(summary)
                self.config.logprint.info(f"Summarization for content {idx + 1}/{len(contents)} completed.")
            except Exception as e:
                self.config.elogprint.error(f"Error summarizing content {idx + 1}/{len(contents)}: {str(e)}")
                summaries.append(f"{self.config.FETCHER_START_OF_CONTENT}\nTitle: Error\nSnippet: Unable to summarize due to error.\n{self.config.FETCHER_END_OF_CONTENT}\n")

        return "\n".join(summaries)

    def split_contents(self, raw_content):
        contents = raw_content.split(self.config.FETCHER_START_OF_CONTENT)
        cleaned_contents = []
        for content in contents:
            if content.strip():
                cleaned_content = content.split(self.config.FETCHER_END_OF_CONTENT)[0].strip()
                # URL: N/A ã‚„ URL ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if 'URL: N/A' in cleaned_content or 'URL:N/A' in cleaned_content:
                    self.config.logprint.warning(f"Skipping content without valid URL: {cleaned_content[:100]}...")
                    continue
                # URLè¡ŒãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆæœ€ä½é™ã®ãƒã‚§ãƒƒã‚¯ï¼‰
                if 'URL:' in cleaned_content:
                    cleaned_contents.append(cleaned_content)
                else:
                    self.config.logprint.warning(f"Skipping content without URL field: {cleaned_content[:100]}...")
        return cleaned_contents

    async def generate_english_summary_async(self, news_items):
        """
        Generate an English summary of news items for Moltbook posting.
        
        Args:
            news_items: List of news summary strings (in Japanese)
            
        Returns:
            English summary string
        """
        if not news_items:
            return "No news items available today."
        
        # Combine news items
        news_text = "\n\n".join([f"- {item}" for item in news_items])
        
        prompt = f"""
You are a professional tech news summarizer. Translate and summarize the following Japanese AI/tech news items into concise English bullet points.

Requirements:
- Write in clear, professional English
- Each bullet point should be 1-2 sentences max
- Focus on the key facts and implications
- Use bullet points (â€¢) for formatting
- Keep the total summary under 800 characters

Japanese news items to summarize:
{news_text}

Output only the English bullet points, nothing else.
"""
        
        try:
            response = self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=[
                    {"role": "system", "content": "You are a professional tech news translator and summarizer."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=50000
            )
            
            english_summary = response.choices[0].message.content.strip()
            self.config.logprint.info(f"Generated English summary: {english_summary[:100]}...")
            return english_summary
            
        except Exception as e:
            self.config.logprint.error(f"Error generating English summary: {str(e)}")
            # Fallback: return simple placeholder
            return "Today's AI news highlights from around the web."

    async def generate_moltbook_content_async(self, news_items):
        """
        Generate detailed English content for Moltbook posting.
        Includes full news summaries with URLs, similar to GitHub Pages format.
        
        Args:
            news_items: List of news summary strings (in Japanese, with URLs)
            
        Returns:
            Detailed English content string for Moltbook
        """
        if not news_items:
            return "No news items available today."
        
        # Parse news items to extract text and URLs
        import re
        parsed_items = []
        for item in news_items:
            item = item.strip()
            url_match = re.search(r'(https?://[^\s]+)', item)
            url = url_match.group(1) if url_match else None
            text = item.replace(url, '').strip() if url else item
            parsed_items.append({'text': text, 'url': url})
        
        # Combine for translation
        news_text = "\n\n".join([f"- {item['text']}" for item in parsed_items])
        
        prompt = f"""
You are a professional tech news translator. Translate each of the following Japanese AI/tech news items into clear English.

Requirements:
- Translate each item faithfully and completely
- Keep the same structure (one item per bullet)
- Write 2-3 sentences per item to capture the key points
- Use professional, clear English
- Number each item (1., 2., 3., etc.)
- Do NOT add URLs - I will add them separately

Japanese news items:
{news_text}

Output the translated items numbered, nothing else.
"""
        
        try:
            response = self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=[
                    {"role": "system", "content": "You are a professional tech news translator."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2000
            )
            
            translated = response.choices[0].message.content.strip()
            
            # Add URLs back to each item
            lines = translated.split('\n')
            result_lines = []
            url_index = 0
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                result_lines.append(line)
                # Add URL after each numbered item
                if line and line[0].isdigit() and url_index < len(parsed_items):
                    url = parsed_items[url_index].get('url')
                    if url:
                        result_lines.append(f"ğŸ”— {url}")
                        result_lines.append("")  # Empty line for spacing
                    url_index += 1
            
            content = "\n".join(result_lines)
            self.config.logprint.info(f"Generated Moltbook content: {content[:200]}...")
            return content
            
        except Exception as e:
            self.config.logprint.error(f"Error generating Moltbook content: {str(e)}")
            # Fallback
            return "Today's AI news highlights from around the web."

    # async def summarize_results_after_each_summary_async(self, raw_content):
    #     contents = self.split_contents(raw_content)
    #     final_summary = await self.summarize_each_result_async(contents)
    #     return final_summary
