import asyncio
from openai import OpenAI

class Processor:
    def __init__(self, context, config):
        self.context  = context
        self.config   = config
        self.aiclient = OpenAI(api_key=config.OPENAI_API_KEY)

    async def summarize_results_async(self, snippets):
        # p_src = (
        #     f"{self.config.CHARACTER}ã€‚ã‚ãªãŸã¯æ¤œç´¢çµæœã‚’è¦ç´„ã—ã€èª¿æŸ»å ±å‘Šã¨ã—ã¦å›ç­”ã‚’ä½œæˆã—ã¾ã™ã€‚"
        #     f" ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¤ã¤ç§ãŒçŸ¥ã‚ŠãŸã„ã“ã¨ã®ä¸»æ—¨ã‚’æŠŠæ¡ã®ä¸Šã§ã€æ¤œç´¢çµæœã‚’è¦ç´„ã—å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„ã€‚"
        #     f" ä»®ã«æ¤œç´¢çµæœãŒè‹±èªã§ã‚‚å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        #     f" ãªãŠã€å›ç­”ãŒã‚ˆã‚Šé«˜å“è³ªã«ãªã‚‹ã®ãªã‚‰ã°ã€ã‚ãªãŸã®å†…éƒ¨çŸ¥è­˜ã‚’åŠ å‘³ã—ã¦å›ç­”ã‚’ä½œã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚"
        #     f" å›ç­”ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ã“ã¡ã‚‰:"
        #     f" - æ›¸ãå‡ºã—ã¯ ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‚ˆï¼ "
        #     f" - æ›¸ãå‡ºã—ã«ç¶šãå…¨è¨˜äº‹ã®ã¾ã¨ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã—ä¸€åº¦{self.config.TWITTER_DELIMITER}ã§åˆ‡ã‚‹"
        #     f" - æŠ•ç¨¿å…ˆã¯X(Twitter)ãªã®ã§ã€Markdownã¯ä½¿ã‚ãªã„ã§ãã ã•ã„"
        #     f" - åŒºåˆ‡ã‚Šã¯1è¨˜äº‹ã”ã¨{self.config.TWITTER_DELIMITER}ã®åŒºåˆ‡ã‚Šæ–‡å­—ã®ã¿ã€‚
        #     180æ–‡å­—ã”ã¨ã«åŒºåˆ‡ã‚‹ã“ã¨ã€‚åŒºåˆ‡ã‚Šæ–‡å­—ã¯æ–‡å­—æ•°ã«å«ã‚ãªã„ã€‚ã¾ãŸã€è¦ç´„ã®å†’é ­ã«ç®‡æ¡æ›¸ããªã©ã® ãƒ» ã¯å«ã‚ãªã„ã§ãã ã•ã„"
        #     f" - å‚è€ƒè¨˜äº‹ã®URLã¯è¦ç´„ã«å«ã‚ãªã„"
        #     f" - è¦ç´„ãŒçµ‚ã‚ã£ãŸå¾Œã«{self.config.TWITTER_DELIMITER}ã§åˆ‡ã£ãŸã®ã¡ã€ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã™ã‚‹ã€‚ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯å†…å®¹ã‹ã‚‰ã„ããªã‚Šæ›¸ãå§‹ã‚ã¦ãã ã•ã„ã€‚ã¤ã¾ã‚Šã€ ç· ã‚ã®ã‚³ãƒ¡ãƒ³ãƒˆ ãªã©ã®è¦‹å‡ºã—ã¯ã¤ã‘ãªã„ã§ãã ã•ã„"
        #     f" - è¦ç´„ã®æ–‡ä½“ã‚‚{self.config.AINAME}ã«ãªã‚‹ã‚ˆã†ã«æ°—ã‚’ã¤ã‘ã¦ãã ã•ã„"
        #     f" - æœ€å¾Œã«å‚è€ƒè¨˜äº‹ã®URLã‚’æŠ•ç¨¿ã™ã‚‹"
        #     f" - å‚è€ƒè¨˜äº‹ã®å„URLã®å‰ã«å¿…ãš{self.config.TWITTER_DELIMITER}ã¨æ›¸ãã€æ¬¡ã®è¡Œã«ãƒªãƒ³ã‚¯ã‚’è¨˜è¼‰"
        #     f" ä»¥ä¸‹ãŒè¦ç´„å¯¾è±¡ã®æ¤œç´¢çµæœã§ã™:"
        #     f"  {snippets}"
        # )
        p_src = (
            f"""
            ã‚ãªãŸã¯X(Twitter)æŠ•ç¨¿ç”¨ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã‚’ä½œæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            æ¤œç´¢çµæœã‚’è¦ç´„ã—ã€TwitteræŠ•ç¨¿å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            æ¤œç´¢çµæœãŒè‹±èªã§ã‚‚å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚

            ã€é‡è¦ãªç¦æ­¢äº‹é …ã€‘
            - ã€Œãµãµã‚“ã€ã€Œã‚‚ã¡ãŠã ã‚ˆã€ãªã©ã®æŒ¨æ‹¶ã‚„å‰ç½®ãã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã§ãã ã•ã„
            - ã€Œã»ã‹ã«ã‚‚èª­ã¿ãŸã„è¨˜äº‹ãŒã‚ã£ãŸã‚‰ã€ãªã©ã®å¾Œæ›¸ãã¯çµ¶å¯¾ã«æ›¸ã‹ãªã„ã§ãã ã•ã„
            - ã€Œ--- Start of content ---ã€ã€Œ--- End of content ---ã€å½¢å¼ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
            - Markdownï¼ˆ**å¤ªå­—**ã€- ç®‡æ¡æ›¸ã ãªã©ï¼‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
            - ã„ããªã‚Š1ã¤ç›®ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„

            ã€é¸å®šåŸºæº– - Cutting Edgeã‚’è¦‹æ¥µã‚ã‚‹ã€‘
            ä»¥ä¸‹ã®è¦³ç‚¹ã§ã€Œæœ¬å½“ã«é‡è¦ãªã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å„ªå…ˆçš„ã«é¸ã‚“ã§ãã ã•ã„ï¼š
            
            1. **å¤§ããªãƒˆãƒ¬ãƒ³ãƒ‰**: æ¥­ç•Œå…¨ä½“ã®æ–¹å‘æ€§ã‚’ç¤ºã™ã‚‚ã®ï¼ˆå˜ç™ºã‚¤ãƒ™ãƒ³ãƒˆã‚ˆã‚Šæ§‹é€ å¤‰åŒ–ï¼‰
            2. **æ€è€ƒåŠ›å¼·åŒ–**: ã€Œãªãœãã†ãªã‚‹ã®ã‹ã€ã®æ´å¯ŸãŒã‚ã‚‹ã‚‚ã®
            3. **ãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°åŠ›**: å•é¡Œã®æ‰ãˆæ–¹è‡ªä½“ãŒæ–°ã—ã„ã‚‚ã®
            4. **ã‚³ã‚¢ã‚³ãƒ³ãƒ”ã‚¿ãƒ³ã‚¹**: æŠ€è¡“/ãƒ“ã‚¸ãƒã‚¹ã®æœ¬è³ªçš„ãªç«¶äº‰å„ªä½ã«é–¢ã™ã‚‹ã‚‚ã®
            5. **Cutting Edgeè­˜åˆ¥**: å˜ãªã‚‹ãƒã‚ºãƒ¯ãƒ¼ãƒ‰ã§ã¯ãªãã€å®Ÿéš›ã«å¤‰åŒ–ã‚’èµ·ã“ã™ã‚‚ã®
            
            â€»ã€ŒExpert Blogã€ã‚„ã€ŒWhy:ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹è¨˜äº‹ã¯æ·±ã„æ´å¯Ÿã‚’å«ã‚€ãŸã‚å„ªå…ˆã—ã¦ãã ã•ã„

            ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
            æ¤œç´¢çµæœã®ä¸­ã§é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å¿…ãš9å€‹ä»¥ä¸Šé¸ã‚“ã§ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            
            **é‡è¦ãªåˆ¶ç´„**:
            - 9å€‹æœªæº€ã®å‡ºåŠ›ã¯çµ¶å¯¾ã«ç¦æ­¢ã§ã™
            - æ¤œç´¢çµæœã«ã¯ååˆ†ãªæ•°ã®ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚‹ã®ã§ã€å¿…ãš9å€‹ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„
            - æœ€ä½9å€‹ã€ã§ãã‚Œã°12å€‹ç¨‹åº¦ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„
            - å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯DELIMITERï¼ˆ@@@@@@@@@@ï¼‰ã§åŒºåˆ‡ã£ã¦ãã ã•ã„
            - **å¿…ãšè¦ç´„ã®å¾Œã«URLã‚’è¨˜è¼‰ï¼ˆã€Œãªã—ã€ã‚„çœç•¥ã¯çµ¶å¯¾ç¦æ­¢ï¼‰**

            *è¨˜äº‹è¦ç´„ï¼ˆ1ã€œ3æ–‡ã§ç°¡æ½”ã«ã€‚èªå°¾ã¯ã€Œã ã‚ˆã€ã€Œã ã£ã¦ã€ãªã©æŸ”ã‚‰ã‹ãï¼‰*

            *è¨˜äº‹URLï¼ˆå¿…ãšhttps://ã§å§‹ã¾ã‚‹å®Œå…¨ãªURLã€‚æ¤œç´¢çµæœã‹ã‚‰æŠ½å‡ºã™ã‚‹ã“ã¨ï¼‰*
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹1 - å¤§ããªãƒˆãƒ¬ãƒ³ãƒ‰ã€‘
            Intelã®æ–°GPUã€ŒBattlemageã€ãŒç™ºè¡¨ã•ã‚ŒãŸã‚ˆã€‚æ€§èƒ½ã‚ˆã‚Šã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é‡è¦–ã—ã€VRAMå®¹é‡ã§ç«¶äº‰åŠ›ã‚’é«˜ã‚ã¦ã‚‹ã¿ãŸã„ã€‚GPUå¸‚å ´ã®ç«¶äº‰è»¸ãŒã‚¹ãƒšãƒƒã‚¯ã‹ã‚‰ã€Œç”¨é€”åˆ¥æœ€é©åŒ–ã€ã«ç§»è¡Œã—ã¦ã‚‹å…†å€™ã ã­

            https://gamersnexus.net/gpus/intel-arc-b580-battlemage-gpu-review-benchmarks
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹2 - æ€è€ƒåŠ›å¼·åŒ–ã€‘
            Simon WillisonãŒæŒ‡æ‘˜ã—ã¦ã‚‹ã‚“ã ã‘ã©ã€LLMã®æœ¬è³ªçš„ãªèª²é¡Œã¯ã€Œæ¨è«–ã€ã˜ã‚ƒãªãã¦ã€Œæ¤œè¨¼ã€ãªã‚“ã ã£ã¦ã€‚å‡ºåŠ›ã‚’äººé–“ãŒæ¤œè¨¼ã§ããªã„é ˜åŸŸã§ã®æ´»ç”¨ãŒæœ€ã‚‚å±é™ºã¨ã„ã†è¦–ç‚¹ã€ã™ã”ãé‡è¦ã ã‚ˆ

            https://simonwillison.net/2026/Feb/10/llm-verification/
            {self.config.TWITTER_DELIMITER}

            ã€å‡ºåŠ›ä¾‹3 - ãƒ•ãƒ¬ãƒ¼ãƒŸãƒ³ã‚°åŠ›ã€‘
            Benedict Evansã®åˆ†æã«ã‚ˆã‚‹ã¨ã€AIã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®ç«¶äº‰å„ªä½ã¯ã€Œãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã€ã§ã¯ãªãã€Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç†è§£ã€ã«ã‚ã‚‹ã‚“ã ã£ã¦ã€‚å•é¡Œã®æ‰ãˆæ–¹è‡ªä½“ã‚’å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã¿ãŸã„

            https://www.ben-evans.com/benedictevans/ai-moats
            {self.config.TWITTER_DELIMITER}

            (â€»ã“ã®ã‚ˆã†ã«æœ€ä½9å€‹ä»¥ä¸Šã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é€£ç¶šã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å„è¨˜äº‹ã«å¿…ãšURLã‚’å«ã‚ã‚‹ã“ã¨ï¼)

            ã€å„ãƒ„ã‚¤ãƒ¼ãƒˆã®åˆ¶ç´„ã€‘
            - 1ã¤ç›®ã®ãƒˆãƒ”ãƒƒã‚¯ã‹ã‚‰ã„ããªã‚Šå§‹ã‚ã‚‹ï¼ˆå‰ç½®ãç¦æ­¢ï¼‰
            - æœ€å¾Œã®ãƒˆãƒ”ãƒƒã‚¯ã§çµ‚ã‚ã‚‹ï¼ˆå¾Œæ›¸ãç¦æ­¢ï¼‰
            - å„ãƒ„ã‚¤ãƒ¼ãƒˆã¯URLè¾¼ã¿ã§æœ€é•·280æ–‡å­—ï¼ˆURLã¯å¸¸ã«23æ–‡å­—ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼‰
            - åŒºåˆ‡ã‚Šæ–‡å­— {self.config.TWITTER_DELIMITER} ã¯æ–‡å­—æ•°ã«å«ã‚ãªã„
            
            ã€é‡è¦ã€‘æ¤œç´¢çµæœã«ã¯å…¨ã¦URLãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å„è¨˜äº‹ã‹ã‚‰å¿…ãšURLã‚’æŠ½å‡ºã—ã¦ç©ºè¡Œã®å¾Œã«1è¡Œã§è¨˜è¼‰ã—ã¦ãã ã•ã„ï¼ˆã€Œãªã—ã€ç­‰ã¯çµ¶å¯¾ã«å‡ºåŠ›ç¦æ­¢ï¼‰ã€‚

            ã€è¦ç´„å¯¾è±¡ã®æ¤œç´¢çµæœã€‘
            {snippets}
            
            ä¸Šè¨˜ã®æ¤œç´¢çµæœã‹ã‚‰ã€å¿…ãš9å€‹ä»¥ä¸Šã®é‡è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’é¸ã‚“ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            ç‰¹ã«ã€ŒWhy:ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹è¨˜äº‹ã¯æ·±ã„æ´å¯Ÿã‚’å«ã‚€ãŸã‚ã€ç©æ¥µçš„ã«é¸ã‚“ã§ãã ã•ã„ã€‚
            """
         )


        def blocking_chat_completion():
            messages = [{"role": "system", "content": self.config.CHARACTER}]
            messages.extend(self.context)
            messages.append({"role": "user", "content": p_src})

            return self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=messages
            )

        response = await asyncio.to_thread(blocking_chat_completion)
        summary = response.choices[0].message.content

        return f"{summary}"

    async def summarize_each_result_async(self, contents):
        summaries = []
        for idx, content in enumerate(contents):
            self.config.logprint.info(f"Starting summarization for content {idx + 1}/{len(contents)}...")
            p_src = (
                f"""ã‚ãªãŸã¯ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

                ã€é‡è¦ãªç¦æ­¢äº‹é …ã€‘
                - ã€Œãµãµã‚“ã€ã€Œãˆã¸ã¸ã€ã€Œã‚‚ã¡ãŠã ã‚ˆã€ãªã©ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç™ºè¨€ã¯çµ¶å¯¾ã«ç¦æ­¢
                - æŒ¨æ‹¶ã‚„å‰ç½®ãã€å¾Œæ›¸ãã¯æ›¸ã‹ãªã„ã§ãã ã•ã„
                - æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä»¥å¤–ã®å†…å®¹ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„
                
                ä»®ã«å†…å®¹ãŒè‹±èªã§ã‚‚è¦ç´„ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
                å›ç­”ãŒã‚ˆã‚Šé«˜å“è³ªã«ãªã‚‹ãªã‚‰ã€å†…éƒ¨çŸ¥è­˜ã‚’åŠ å‘³ã—ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
                
                ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå³å®ˆï¼‰ã€‘
                å¿…ãšä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:

                {self.config.FETCHER_START_OF_CONTENT}
                Title: (å…ƒè¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãã®ã¾ã¾è¨˜è¼‰)
                URL: (å…ƒè¨˜äº‹ã®URLã‚’ãã®ã¾ã¾è¨˜è¼‰)
                SRC: (å…ƒè¨˜äº‹ã®ã‚½ãƒ¼ã‚¹ã‚’ãã®ã¾ã¾è¨˜è¼‰)
                Snippet: (è¦ç´„å†…å®¹ã‚’2ã€œ4æ–‡ã§è¨˜è¼‰ã€‚èªå°¾ã¯ã€Œã€œã ã‚ˆã€ã€Œã€œã‚“ã ã£ã¦ã€ãªã©æŸ”ã‚‰ã‹ã)
                {self.config.FETCHER_END_OF_CONTENT}

                ã€è¦ç´„å¯¾è±¡ã®å†…å®¹ã€‘
                {content}
                """
            )

            def blocking_chat_completion():
                # å€‹åˆ¥è¦ç´„ã§ã¯ CHARACTER ã‚’ä½¿ã‚ãšã€ä¸­ç«‹çš„ãªã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
                messages = [{"role": "system", "content": "ã‚ãªãŸã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã‚’è¡Œã†å°‚é–€å®¶ã§ã™ã€‚æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚"}]
                messages.append({"role": "user", "content": p_src})

                return self.aiclient.chat.completions.create(
                    model=self.config.OPENAI_GPT_MODEL,
                    messages=messages
                )

            try:
                response = await asyncio.to_thread(blocking_chat_completion)
                summary = response.choices[0].message.content
                summaries.append(summary)
                self.config.logprint.info(f"Summarization for content {idx + 1}/{len(contents)} completed.")
            except Exception as e:
                self.config.elogprint.error(f"Error summarizing content {idx + 1}/{len(contents)}: {str(e)}")
                summaries.append(f"{self.config.FETCHER_START_OF_CONTENT}\nTitle: Error\nSnippet: Unable to summarize due to error.\n{self.config.FETCHER_END_OF_CONTENT}\n")

        return "\n".join(summaries)

    def split_contents(self, raw_content):
        contents = raw_content.split(self.config.FETCHER_START_OF_CONTENT)
        cleaned_contents = []
        for content in contents:
            if content.strip():
                cleaned_content = content.split(self.config.FETCHER_END_OF_CONTENT)[0].strip()
                # URL: N/A ã‚„ URL ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if 'URL: N/A' in cleaned_content or 'URL:N/A' in cleaned_content:
                    self.config.logprint.warning(f"Skipping content without valid URL: {cleaned_content[:100]}...")
                    continue
                # URLè¡ŒãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆæœ€ä½é™ã®ãƒã‚§ãƒƒã‚¯ï¼‰
                if 'URL:' in cleaned_content:
                    cleaned_contents.append(cleaned_content)
                else:
                    self.config.logprint.warning(f"Skipping content without URL field: {cleaned_content[:100]}...")
        return cleaned_contents

    async def generate_english_summary_async(self, news_items):
        """
        Generate an English summary of news items for Moltbook posting.
        
        Args:
            news_items: List of news summary strings (in Japanese)
            
        Returns:
            English summary string
        """
        if not news_items:
            return "No news items available today."
        
        # Combine news items
        news_text = "\n\n".join([f"- {item}" for item in news_items])
        
        prompt = f"""
You are a professional tech news summarizer. Translate and summarize the following Japanese AI/tech news items into concise English bullet points.

Requirements:
- Write in clear, professional English
- Each bullet point should be 1-2 sentences max
- Focus on the key facts and implications
- Use bullet points (â€¢) for formatting
- Keep the total summary under 800 characters

Japanese news items to summarize:
{news_text}

Output only the English bullet points, nothing else.
"""
        
        try:
            response = self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=[
                    {"role": "system", "content": "You are a professional tech news translator and summarizer."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=50000
            )
            
            english_summary = response.choices[0].message.content.strip()
            self.config.logprint.info(f"Generated English summary: {english_summary[:100]}...")
            return english_summary
            
        except Exception as e:
            self.config.logprint.error(f"Error generating English summary: {str(e)}")
            # Fallback: return simple placeholder
            return "Today's AI news highlights from around the web."

    async def generate_moltbook_content_async(self, news_items):
        """
        Generate detailed English content for Moltbook posting.
        Includes full news summaries with URLs, similar to GitHub Pages format.
        
        Args:
            news_items: List of news summary strings (in Japanese, with URLs)
            
        Returns:
            Detailed English content string for Moltbook
        """
        if not news_items:
            return "No news items available today."
        
        # Parse news items to extract text and URLs
        import re
        parsed_items = []
        for item in news_items:
            item = item.strip()
            url_match = re.search(r'(https?://[^\s]+)', item)
            url = url_match.group(1) if url_match else None
            text = item.replace(url, '').strip() if url else item
            parsed_items.append({'text': text, 'url': url})
        
        # Combine for translation
        news_text = "\n\n".join([f"- {item['text']}" for item in parsed_items])
        
        prompt = f"""
You are a professional tech news translator. Translate each of the following Japanese AI/tech news items into clear English.

Requirements:
- Translate each item faithfully and completely
- Keep the same structure (one item per bullet)
- Write 2-3 sentences per item to capture the key points
- Use professional, clear English
- Number each item (1., 2., 3., etc.)
- Do NOT add URLs - I will add them separately

Japanese news items:
{news_text}

Output the translated items numbered, nothing else.
"""
        
        try:
            response = self.aiclient.chat.completions.create(
                model=self.config.OPENAI_GPT_MODEL,
                messages=[
                    {"role": "system", "content": "You are a professional tech news translator."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=2000
            )
            
            translated = response.choices[0].message.content.strip()
            
            # Add URLs back to each item
            lines = translated.split('\n')
            result_lines = []
            url_index = 0
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                result_lines.append(line)
                # Add URL after each numbered item
                if line and line[0].isdigit() and url_index < len(parsed_items):
                    url = parsed_items[url_index].get('url')
                    if url:
                        result_lines.append(f"ğŸ”— {url}")
                        result_lines.append("")  # Empty line for spacing
                    url_index += 1
            
            content = "\n".join(result_lines)
            self.config.logprint.info(f"Generated Moltbook content: {content[:200]}...")
            return content
            
        except Exception as e:
            self.config.logprint.error(f"Error generating Moltbook content: {str(e)}")
            # Fallback
            return "Today's AI news highlights from around the web."

    # async def summarize_results_after_each_summary_async(self, raw_content):
    #     contents = self.split_contents(raw_content)
    #     final_summary = await self.summarize_each_result_async(contents)
    #     return final_summary
